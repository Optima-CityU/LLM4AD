"""
LLM4AD Chat Interface - Main Application
ä¸€ä¸ªåŸºäºå¯¹è¯çš„è‡ªåŠ¨ç®—æ³•è®¾è®¡äº¤äº’ç•Œé¢

ä½¿ç”¨æ–¹æ³•:
    cd LLM4AD
    streamlit run chat_interface/chat_app.py
"""

import os
import sys
import time
import streamlit as st
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from chat_interface.chat_agent import ChatAgent
from chat_interface.config_manager import ConfigManager
from chat_interface.components import render_config_panel, render_result_card
from chat_interface.algorithm_runner import AlgorithmRunner

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="LLM4AD - è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½è‡ªå®šä¹‰æ ·å¼
def load_custom_css():
    css = """
    <style>
    /* æ•´ä½“é£æ ¼ - ç§‘ç ”é£æ ¼ï¼Œç®€æ´ä¸“ä¸š */
    .main {
        background-color: #fafbfc;
    }
    
    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 0.75rem;
        display: flex;
        flex-direction: column;
    }
    
    .chat-message.user {
        background-color: #e8f4fd;
        border-left: 4px solid #1976d2;
    }
    
    .chat-message.assistant {
        background-color: #f5f5f5;
        border-left: 4px solid #424242;
    }
    
    .chat-message .message-content {
        margin-top: 0.5rem;
    }
    
    /* ä»£ç å—æ ·å¼ */
    .code-block {
        background-color: #1e1e1e;
        color: #d4d4d4;
        padding: 1rem;
        border-radius: 0.5rem;
        font-family: 'Consolas', 'Monaco', monospace;
        font-size: 0.85rem;
        overflow-x: auto;
        margin: 0.5rem 0;
    }
    
    /* ç»“æœå¡ç‰‡æ ·å¼ */
    .result-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 1rem;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .result-card h3 {
        margin-bottom: 1rem;
        font-size: 1.2rem;
    }
    
    .result-card .score {
        font-size: 2rem;
        font-weight: bold;
        margin: 0.5rem 0;
    }
    
    /* è¿›åº¦æŒ‡ç¤ºå™¨ */
    .progress-indicator {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        color: #666;
        font-size: 0.9rem;
    }
    
    .progress-indicator .dot {
        width: 8px;
        height: 8px;
        background-color: #4caf50;
        border-radius: 50%;
        animation: pulse 1.5s infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    /* é…ç½®é¢æ¿æ ·å¼ */
    .config-panel {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #e0e0e0;
        margin: 0.5rem 0;
    }
    
    /* çŠ¶æ€å¾½ç«  */
    .status-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 1rem;
        font-size: 0.75rem;
        font-weight: 500;
    }
    
    .status-badge.running {
        background-color: #fff3e0;
        color: #e65100;
    }
    
    .status-badge.completed {
        background-color: #e8f5e9;
        color: #2e7d32;
    }
    
    .status-badge.error {
        background-color: #ffebee;
        color: #c62828;
    }
    
    /* éšè— Streamlit é»˜è®¤å…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background-color: #f8f9fa;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 1.8rem;
        font-weight: 600;
        color: #1a1a2e;
        margin-bottom: 0.5rem;
    }
    
    .sub-title {
        font-size: 0.95rem;
        color: #666;
        margin-bottom: 1.5rem;
    }
    
    /* ç®—æ³•ä»£ç å±•ç¤º */
    .algorithm-display {
        background-color: #282c34;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .algorithm-display pre {
        color: #abb2bf;
        margin: 0;
        white-space: pre-wrap;
        word-wrap: break-word;
    }
    
    /* æµå¼è¾“å‡ºæ ·å¼ */
    .stream-output {
        font-family: 'SF Mono', 'Consolas', monospace;
        font-size: 0.85rem;
        line-height: 1.6;
        color: #333;
    }
    
    /* è¿­ä»£è¿›åº¦ */
    .iteration-info {
        background-color: #f0f7ff;
        border: 1px solid #cce5ff;
        border-radius: 0.5rem;
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        font-size: 0.9rem;
    }
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)


def init_session_state():
    """åˆå§‹åŒ– session state"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "chat_agent" not in st.session_state:
        st.session_state.chat_agent = None
    
    if "config_manager" not in st.session_state:
        st.session_state.config_manager = ConfigManager()
    
    if "algorithm_runner" not in st.session_state:
        st.session_state.algorithm_runner = None
    
    if "current_config" not in st.session_state:
        st.session_state.current_config = {
            "method": None,
            "task": None,
            "llm": None,
            "parameters": {}
        }
    
    if "is_running" not in st.session_state:
        st.session_state.is_running = False
    
    if "show_config_panel" not in st.session_state:
        st.session_state.show_config_panel = False
    
    if "run_results" not in st.session_state:
        st.session_state.run_results = []


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("### âš™ï¸ LLM é…ç½®")
        
        # å¤–å±‚ LLM é…ç½®ï¼ˆç”¨äºå¯¹è¯ï¼‰
        st.markdown("#### å¯¹è¯ LLM")
        outer_host = st.text_input("API Host", value="api.bltcy.top", key="outer_host")
        outer_key = st.text_input("API Key", type="password", key="outer_key")
        outer_model = st.selectbox(
            "æ¨¡å‹", 
            ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo", "claude-3-sonnet"],
            key="outer_model"
        )
        
        st.markdown("---")
        
        # å†…å±‚ LLM é…ç½®ï¼ˆç”¨äºç®—æ³•è®¾è®¡ï¼‰
        st.markdown("#### ç®—æ³•è®¾è®¡ LLM")
        use_same_llm = st.checkbox("ä½¿ç”¨ç›¸åŒé…ç½®", value=True)
        
        if use_same_llm:
            inner_host = outer_host
            inner_key = outer_key
            inner_model = outer_model
        else:
            inner_host = st.text_input("API Host", value="api.bltcy.top", key="inner_host")
            inner_key = st.text_input("API Key", type="password", key="inner_key")
            inner_model = st.selectbox(
                "æ¨¡å‹",
                ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
                key="inner_model"
            )
        
        # å­˜å‚¨é…ç½®
        st.session_state.current_config["llm"] = {
            "outer": {"host": outer_host, "key": outer_key, "model": outer_model},
            "inner": {"host": inner_host, "key": inner_key, "model": inner_model}
        }
        
        st.markdown("---")
        
        # å½“å‰çŠ¶æ€æ˜¾ç¤º
        st.markdown("### ğŸ“Š å½“å‰çŠ¶æ€")
        config = st.session_state.current_config
        
        method_status = f"âœ… {config['method']}" if config['method'] else "âŒ æœªé€‰æ‹©"
        task_status = f"âœ… {config['task']}" if config['task'] else "âŒ æœªé€‰æ‹©"
        
        st.markdown(f"**æ–¹æ³•:** {method_status}")
        st.markdown(f"**ä»»åŠ¡:** {task_status}")
        
        if st.session_state.is_running:
            st.markdown('<span class="status-badge running">ğŸ”„ è¿è¡Œä¸­</span>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # å¿«æ·æ“ä½œ
        st.markdown("### ğŸš€ å¿«æ·æ“ä½œ")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.session_state.current_config = {
                "method": None,
                "task": None,
                "llm": st.session_state.current_config.get("llm"),
                "parameters": {}
            }
            st.rerun()
        
        if st.button("ğŸ“ æ‰‹åŠ¨é…ç½®", use_container_width=True):
            st.session_state.show_config_panel = not st.session_state.show_config_panel
            st.rerun()


def render_chat_message(message):
    """æ¸²æŸ“èŠå¤©æ¶ˆæ¯"""
    role = message["role"]
    content = message["content"]
    
    if role == "user":
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(content)
    else:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šå†…å®¹ç±»å‹
            if isinstance(content, dict):
                if content.get("type") == "algorithm_result":
                    render_result_card(content.get("data", {}))
                elif content.get("type") == "config_form":
                    render_config_panel(content.get("data", {}))
                else:
                    st.markdown(content.get("text", ""))
            else:
                st.markdown(content)


def get_welcome_message():
    """è·å–æ¬¢è¿æ¶ˆæ¯"""
    return """
ğŸ‘‹ **æ¬¢è¿ä½¿ç”¨ LLM4AD è‡ªåŠ¨ç®—æ³•è®¾è®¡å¹³å°ï¼**

æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ï¼š
- ğŸ¯ **é€‰æ‹©ç®—æ³•è®¾è®¡æ–¹æ³•**ï¼šå¦‚ EoHï¼ˆå¯å‘å¼æ¼”åŒ–ï¼‰ã€FunSearchã€éšæœºé‡‡æ ·ç­‰
- ğŸ“‹ **é…ç½®ä¼˜åŒ–ä»»åŠ¡**ï¼šå¦‚åœ¨çº¿è£…ç®±é—®é¢˜ã€TSPè·¯å¾„è§„åˆ’ã€è½¦è¾†è·¯å¾„é—®é¢˜ç­‰
- âš™ï¸ **è®¾ç½®å‚æ•°**ï¼šé‡‡æ ·æ•°é‡ã€ç§ç¾¤å¤§å°ã€è¿­ä»£æ¬¡æ•°ç­‰
- ğŸ”¬ **è¿è¡Œç®—æ³•è®¾è®¡**ï¼šå®æ—¶å±•ç¤ºè®¾è®¡è¿‡ç¨‹å’Œç»“æœ

---

**å¼€å§‹æ–¹å¼ï¼š**
1. ğŸ’¬ ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨æƒ³è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œæˆ‘ä¼šä¸ºæ‚¨æ¨èåˆé€‚çš„æ–¹æ³•
2. ğŸ”§ æˆ–è€…è¯´"æ˜¾ç¤ºé…ç½®é¢æ¿"æ¥æ‰‹åŠ¨è®¾ç½®å‚æ•°
3. â“ å¦‚æœæœ‰ç–‘é—®ï¼Œå¯ä»¥é—®æˆ‘"æœ‰å“ªäº›å¯ç”¨çš„æ–¹æ³•ï¼Ÿ"æˆ–"æœ‰å“ªäº›ä»»åŠ¡ï¼Ÿ"

**ç¤ºä¾‹å¯¹è¯ï¼š**
- "æˆ‘æƒ³ç”¨EoHæ–¹æ³•è§£å†³åœ¨çº¿è£…ç®±é—®é¢˜"
- "å¸®æˆ‘è®¾è®¡ä¸€ä¸ªTSPé—®é¢˜çš„å¯å‘å¼ç®—æ³•"
- "åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¼˜åŒ–æ–¹æ³•"

è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„éœ€æ±‚å¼€å§‹å§ï¼ ğŸ‘‡
"""


def main():
    """ä¸»å‡½æ•°"""
    load_custom_css()
    init_session_state()
    
    # åˆå§‹åŒ– ChatAgent
    if st.session_state.chat_agent is None:
        llm_config = st.session_state.current_config.get("llm", {}).get("outer", {})
        if llm_config.get("key"):
            st.session_state.chat_agent = ChatAgent(
                host=llm_config.get("host", "api.bltcy.top"),
                api_key=llm_config.get("key", ""),
                model=llm_config.get("model", "gpt-4o-mini")
            )
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    render_sidebar()
    
    # ä¸»å†…å®¹åŒº
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # æ ‡é¢˜
        st.markdown('<h1 class="main-title">ğŸ§¬ LLM4AD è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹</h1>', unsafe_allow_html=True)
        st.markdown('<p class="sub-title">é€šè¿‡å¯¹è¯çš„æ–¹å¼ï¼Œè®©AIå¸®æ‚¨è®¾è®¡é«˜æ•ˆçš„ç®—æ³•</p>', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ï¼‰
        if not st.session_state.messages:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(get_welcome_message())
        
        # æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for message in st.session_state.messages:
            render_chat_message(message)
        
        # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œæ˜¾ç¤ºè¿›åº¦
        if st.session_state.is_running:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown("""
                <div class="progress-indicator">
                    <div class="dot"></div>
                    <span>æ­£åœ¨è®¾è®¡ç®—æ³•ä¸­ï¼Œè¯·ç¨å€™...</span>
                </div>
                """, unsafe_allow_html=True)
        
        # èŠå¤©è¾“å…¥
        if prompt := st.chat_input("è¾“å…¥æ‚¨çš„éœ€æ±‚...", disabled=st.session_state.is_running):
            # æ£€æŸ¥ API Key
            llm_config = st.session_state.current_config.get("llm", {}).get("outer", {})
            if not llm_config.get("key"):
                st.error("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
            else:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # å¦‚æœ agent æœªåˆå§‹åŒ–ï¼Œç°åœ¨åˆå§‹åŒ–
                if st.session_state.chat_agent is None:
                    st.session_state.chat_agent = ChatAgent(
                        host=llm_config.get("host", "api.bltcy.top"),
                        api_key=llm_config.get("key", ""),
                        model=llm_config.get("model", "gpt-4o-mini")
                    )
                
                # æ›´æ–° agent é…ç½®
                st.session_state.chat_agent.update_config(
                    host=llm_config.get("host"),
                    api_key=llm_config.get("key"),
                    model=llm_config.get("model")
                )
                
                # è·å–å“åº”
                with st.spinner("æ€è€ƒä¸­..."):
                    response = st.session_state.chat_agent.chat(
                        prompt,
                        st.session_state.current_config,
                        st.session_state.config_manager
                    )
                
                # å¤„ç†å“åº”
                if response.get("action") == "run_algorithm":
                    # éœ€è¦è¿è¡Œç®—æ³•
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response.get("message", "å¥½çš„ï¼Œæˆ‘å°†å¼€å§‹ä¸ºæ‚¨è®¾è®¡ç®—æ³•...")
                    })
                    st.session_state.is_running = True
                    st.session_state.current_config.update(response.get("config", {}))
                    st.rerun()
                    
                elif response.get("action") == "show_config":
                    # æ˜¾ç¤ºé…ç½®é¢æ¿
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": {
                            "type": "config_form",
                            "data": response.get("config_data", {})
                        }
                    })
                    st.session_state.show_config_panel = True
                    st.rerun()
                    
                elif response.get("action") == "update_config":
                    # æ›´æ–°é…ç½®
                    st.session_state.current_config.update(response.get("config", {}))
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response.get("message", "é…ç½®å·²æ›´æ–°ã€‚")
                    })
                    st.rerun()
                    
                else:
                    # æ™®é€šå¯¹è¯å“åº”
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response.get("message", "æˆ‘ä¸å¤ªç†è§£æ‚¨çš„æ„æ€ï¼Œè¯·å†è¯´ä¸€éã€‚")
                    })
                    st.rerun()
    
    with col2:
        # æ‰‹åŠ¨é…ç½®é¢æ¿
        if st.session_state.show_config_panel:
            st.markdown("### ğŸ“‹ å‚æ•°é…ç½®")
            
            with st.form("config_form"):
                # æ–¹æ³•é€‰æ‹©
                methods = st.session_state.config_manager.get_available_methods()
                selected_method = st.selectbox(
                    "é€‰æ‹©æ–¹æ³•",
                    options=[""] + methods,
                    index=0 if not st.session_state.current_config.get("method") 
                          else methods.index(st.session_state.current_config["method"]) + 1 
                          if st.session_state.current_config.get("method") in methods else 0
                )
                
                # ä»»åŠ¡é€‰æ‹©
                tasks = st.session_state.config_manager.get_available_tasks()
                selected_task = st.selectbox(
                    "é€‰æ‹©ä»»åŠ¡",
                    options=[""] + tasks,
                    index=0 if not st.session_state.current_config.get("task")
                          else tasks.index(st.session_state.current_config["task"]) + 1
                          if st.session_state.current_config.get("task") in tasks else 0
                )
                
                st.markdown("---")
                st.markdown("**æ–¹æ³•å‚æ•°**")
                
                # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æ˜¾ç¤ºå‚æ•°
                if selected_method:
                    method_params = st.session_state.config_manager.get_method_parameters(selected_method)
                    param_values = {}
                    for param_name, param_info in method_params.items():
                        if param_info["type"] == "int":
                            param_values[param_name] = st.number_input(
                                param_info.get("label", param_name),
                                value=param_info.get("default", 10),
                                min_value=param_info.get("min", 1),
                                max_value=param_info.get("max", 1000),
                                help=param_info.get("help", "")
                            )
                        elif param_info["type"] == "bool":
                            param_values[param_name] = st.checkbox(
                                param_info.get("label", param_name),
                                value=param_info.get("default", True),
                                help=param_info.get("help", "")
                            )
                
                submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True)
                
                if submitted:
                    if selected_method:
                        st.session_state.current_config["method"] = selected_method
                    if selected_task:
                        st.session_state.current_config["task"] = selected_task
                    if selected_method:
                        st.session_state.current_config["parameters"] = param_values
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âœ… é…ç½®å·²ä¿å­˜ï¼\n- æ–¹æ³•: {selected_method or 'æœªé€‰æ‹©'}\n- ä»»åŠ¡: {selected_task or 'æœªé€‰æ‹©'}"
                    })
                    st.rerun()
            
            # è¿è¡ŒæŒ‰é’®
            if st.session_state.current_config.get("method") and st.session_state.current_config.get("task"):
                if st.button("ğŸš€ å¼€å§‹è®¾è®¡ç®—æ³•", use_container_width=True, type="primary"):
                    st.session_state.is_running = True
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"ğŸš€ å¼€å§‹ä½¿ç”¨ **{st.session_state.current_config['method']}** æ–¹æ³•è®¾è®¡ **{st.session_state.current_config['task']}** ä»»åŠ¡çš„ç®—æ³•..."
                    })
                    st.rerun()
    
    # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œæ‰§è¡Œç®—æ³•è®¾è®¡
    if st.session_state.is_running:
        run_algorithm_design()


def run_algorithm_design():
    """è¿è¡Œç®—æ³•è®¾è®¡"""
    config = st.session_state.current_config
    llm_config = config.get("llm", {}).get("inner", {})
    
    if not llm_config.get("key"):
        st.error("âš ï¸ è¯·å…ˆé…ç½® API Key")
        st.session_state.is_running = False
        return
    
    # åˆ›å»ºç®—æ³•è¿è¡Œå™¨
    runner = AlgorithmRunner(
        method_name=config.get("method"),
        task_name=config.get("task"),
        llm_config=llm_config,
        parameters=config.get("parameters", {})
    )
    
    # åˆ›å»ºè¾“å‡ºå®¹å™¨
    output_container = st.empty()
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # è¿è¡Œç®—æ³•å¹¶æµå¼è¾“å‡º
        result = None
        for update in runner.run_with_stream():
            if update["type"] == "progress":
                progress_bar.progress(update["value"])
                status_text.text(update.get("message", ""))
            elif update["type"] == "log":
                with output_container.container():
                    st.markdown(f"""
                    <div class="iteration-info">
                        <strong>ğŸ“Š ç¬¬ {update.get('iteration', '?')} æ¬¡è¿­ä»£</strong><br>
                        å½“å‰å¾—åˆ†: {update.get('score', 'N/A')}<br>
                        æœ€ä½³å¾—åˆ†: {update.get('best_score', 'N/A')}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if update.get("code"):
                        st.code(update["code"], language="python")
            elif update["type"] == "result":
                result = update["data"]
        
        # å®Œæˆ
        st.session_state.is_running = False
        progress_bar.progress(100)
        status_text.text("âœ… ç®—æ³•è®¾è®¡å®Œæˆï¼")
        
        if result:
            # æ·»åŠ ç»“æœæ¶ˆæ¯
            st.session_state.messages.append({
                "role": "assistant",
                "content": {
                    "type": "algorithm_result",
                    "data": result
                }
            })
            
            # æ·»åŠ æ–‡å­—æ€»ç»“
            summary = f"""
ğŸ‰ **ç®—æ³•è®¾è®¡å®Œæˆï¼**

**æœ€ç»ˆç»“æœï¼š**
- ğŸ† æœ€ä½³å¾—åˆ†: **{result.get('best_score', 'N/A')}**
- ğŸ“Š æ€»é‡‡æ ·æ•°: {result.get('total_samples', 'N/A')}
- â±ï¸ æ€»è€—æ—¶: {result.get('total_time', 'N/A')}ç§’

**æœ€ä½³ç®—æ³•ä»£ç ï¼š**
```python
{result.get('best_code', '# æ— æ³•è·å–ä»£ç ')}
```

æ‚¨å¯ä»¥ç»§ç»­ä¸æˆ‘å¯¹è¯ï¼Œä¼˜åŒ–å‚æ•°æˆ–å°è¯•å…¶ä»–æ–¹æ³•ã€‚
            """
            st.session_state.messages.append({
                "role": "assistant",
                "content": summary
            })
        
        st.rerun()
        
    except Exception as e:
        st.session_state.is_running = False
        st.error(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        st.session_state.messages.append({
            "role": "assistant",
            "content": f"âŒ ç®—æ³•è®¾è®¡è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\n\nè¯·æ£€æŸ¥é…ç½®åé‡è¯•ã€‚"
        })
        st.rerun()


if __name__ == "__main__":
    main()

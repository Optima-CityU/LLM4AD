"""
LLM4AD Chat Interface - Main Application
ä¸€ä¸ªåŸºäºå¯¹è¯çš„è‡ªåŠ¨ç®—æ³•è®¾è®¡äº¤äº’ç•Œé¢

æ‰€æœ‰å¯¹è¯éƒ½é€šè¿‡å¤–éƒ¨LLMå®ç°ï¼Œä½¿ç”¨OpenAI Function Callingé£æ ¼çš„å·¥å…·è°ƒç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
    cd LLM4AD
    streamlit run chat_interface/app.py
"""

import os
import sys
import time
import json
import streamlit as st
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from chat_interface.tool_agent import ToolCallingAgent
from chat_interface.config_manager import ConfigManager
from chat_interface.algorithm_runner import create_runner

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="LLM4AD - è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== è‡ªå®šä¹‰ CSS æ ·å¼ ==========
def load_custom_css():
    st.markdown("""
    <style>
    /* å…¨å±€æ ·å¼ */
    .stApp {
        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    }
    
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        background: linear-gradient(90deg, #00d4ff, #7b2cbf, #ff6b6b);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2.5rem;
        font-weight: 800;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 0;
    }
    
    .sub-title {
        color: #a0a0a0;
        text-align: center;
        font-size: 1rem;
        margin-top: 0;
        margin-bottom: 2rem;
    }
    
    /* Streamlit èŠå¤©æ¶ˆæ¯ç¾åŒ– */
    .stChatMessage {
        background: transparent !important;
        padding: 0.5rem 0 !important;
    }
    
    /* ç”¨æˆ·æ¶ˆæ¯ */
    [data-testid="stChatMessageContent"]:has(.stMarkdown) {
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
        white-space: pre-wrap !important;
    }
    
    /* æ¶ˆæ¯å†…å®¹è‡ªåŠ¨æ¢è¡Œ */
    .stMarkdown {
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
    }
    
    .stMarkdown p {
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
        white-space: pre-wrap !important;
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* çŠ¶æ€å¡ç‰‡ */
    .status-card {
        background: linear-gradient(135deg, rgba(45, 55, 72, 0.8) 0%, rgba(26, 32, 44, 0.9) 100%);
        border-radius: 1rem;
        padding: 1rem;
        border: 1px solid #4a5568;
        margin-bottom: 1rem;
    }
    
    .status-card.success { border-left: 4px solid #48bb78; }
    .status-card.warning { border-left: 4px solid #ed8936; }
    .status-card.info { border-left: 4px solid #4299e1; }
    
    /* æŒ‰é’®æ ·å¼å¢å¼º */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 0.75rem !important;
        padding: 0.75rem 1.5rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4) !important;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6) !important;
    }
    
    /* åˆ†éš”çº¿ */
    .divider {
        height: 1px;
        background: linear-gradient(90deg, transparent, #4a5568, transparent);
        margin: 1.5rem 0;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: linear-gradient(135deg, #2d3748 0%, #1a202c 100%);
        border-radius: 1rem;
        padding: 1.5rem;
        text-align: center;
        border: 1px solid #4a5568;
        transition: transform 0.2s;
    }
    
    .metric-card:hover { transform: translateY(-3px); }
    .metric-card .value { font-size: 2rem; font-weight: 700; background: linear-gradient(90deg, #48bb78, #38a169); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    .metric-card .label { font-size: 0.85rem; color: #a0aec0; margin-top: 0.25rem; }
    
    /* è¿›åº¦æ¡ */
    .stProgress > div > div > div {
        background: linear-gradient(90deg, #667eea, #764ba2) !important;
    }
    
    /* æ¬¢è¿å¡ç‰‡ */
    .welcome-card {
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.15) 0%, rgba(118, 75, 162, 0.15) 100%);
        border: 1px solid rgba(102, 126, 234, 0.3);
        border-radius: 1rem;
        padding: 2rem;
        margin-bottom: 2rem;
    }
    
    /* å·¥å…·è°ƒç”¨æ ‡ç­¾ */
    .tool-badge {
        display: inline-block;
        background: linear-gradient(135deg, #4299e1 0%, #3182ce 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 1rem;
        font-size: 0.75rem;
        margin-right: 0.5rem;
        margin-bottom: 0.5rem;
    }
    
    /* éšè— Streamlit é»˜è®¤å…ƒç´  */
    footer {visibility: hidden;}
    #MainMenu {visibility: hidden;}
    
    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    .running-indicator { animation: pulse 1.5s infinite; }
    
    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput > div > div > input {
        border-radius: 0.75rem !important;
    }
    
    /* ä¸‹æ‹‰æ¡†ç¾åŒ– */
    .stSelectbox > div > div {
        border-radius: 0.75rem !important;
    }
    </style>
    """, unsafe_allow_html=True)


def init_session_state():
    """åˆå§‹åŒ– session state"""
    defaults = {
        "messages": [],
        "chat_agent": None,
        "config_manager": ConfigManager(),
        "current_config": {
            "method": None,
            "task": None,
            "llm": {"outer": {}, "inner": {}},
            "parameters": {}
        },
        "is_running": False,
        "show_config_panel": False,
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ  - ç¾åŒ–ç‰ˆ"""
    with st.sidebar:
        # Logo å’Œæ ‡é¢˜
        st.markdown("""
        <div style="text-align: center; padding: 1rem 0;">
            <div style="font-size: 3rem;">ğŸ§¬</div>
            <div style="font-size: 1.5rem; font-weight: 700; 
                        background: linear-gradient(90deg, #00d4ff, #7b2cbf);
                        -webkit-background-clip: text; -webkit-text-fill-color: transparent;">
                LLM4AD
            </div>
            <div style="color: #718096; font-size: 0.85rem;">è‡ªåŠ¨ç®—æ³•è®¾è®¡å¹³å°</div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # LLM é…ç½®
        st.markdown("#### ğŸ¤– API é…ç½®")
        
        api_host = st.text_input(
            "API Host", 
            value=st.session_state.current_config["llm"].get("outer", {}).get("host", "api.bltcy.top"),
            key="api_host",
            help="OpenAI å…¼å®¹çš„ API åœ°å€"
        )
        
        api_key = st.text_input(
            "API Key", 
            type="password",
            value=st.session_state.current_config["llm"].get("outer", {}).get("key", ""),
            key="api_key",
            help="æ‚¨çš„ API å¯†é’¥"
        )
        
        api_model = st.selectbox(
            "æ¨¡å‹",
            ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo", "deepseek-chat", "claude-3-sonnet"],
            key="api_model"
        )
        
        # æ›´æ–°é…ç½®
        st.session_state.current_config["llm"] = {
            "outer": {"host": api_host, "key": api_key, "model": api_model},
            "inner": {"host": api_host, "key": api_key, "model": api_model}
        }
        
        # å¦‚æœ API Key å˜äº†ï¼Œé‡ç½® agent
        if api_key and st.session_state.chat_agent:
            if st.session_state.chat_agent.api_key != api_key:
                st.session_state.chat_agent = None
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # å½“å‰çŠ¶æ€ - ç¾åŒ–å¡ç‰‡
        st.markdown("#### ğŸ“Š è¿è¡ŒçŠ¶æ€")
        config = st.session_state.current_config
        
        method = config.get("method")
        task = config.get("task")
        
        # æ–¹æ³•çŠ¶æ€
        if method:
            st.markdown(f"""
            <div class="status-card success">
                <div style="color: #48bb78; font-weight: 600;">âœ“ æ–¹æ³•</div>
                <div style="color: #f0f0f0; font-size: 1.1rem;">{method}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="status-card warning">
                <div style="color: #ed8936; font-weight: 600;">â—‹ æ–¹æ³•</div>
                <div style="color: #a0aec0;">æœªé€‰æ‹©</div>
            </div>
            """, unsafe_allow_html=True)
        
        # ä»»åŠ¡çŠ¶æ€
        if task:
            st.markdown(f"""
            <div class="status-card success">
                <div style="color: #48bb78; font-weight: 600;">âœ“ ä»»åŠ¡</div>
                <div style="color: #f0f0f0; font-size: 1.1rem;">{task}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="status-card warning">
                <div style="color: #ed8936; font-weight: 600;">â—‹ ä»»åŠ¡</div>
                <div style="color: #a0aec0;">æœªé€‰æ‹©</div>
            </div>
            """, unsafe_allow_html=True)
        
        # è¿è¡ŒçŠ¶æ€
        if st.session_state.is_running:
            st.markdown("""
            <div class="status-card info running-indicator">
                <div style="color: #4299e1; font-weight: 600;">âš¡ è¿è¡Œä¸­</div>
                <div style="color: #a0aec0;">ç®—æ³•è®¾è®¡è¿›è¡Œä¸­...</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # å¿«æ·æ“ä½œ
        st.markdown("#### ğŸ® å¿«æ·æ“ä½œ")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True, help="æ¸…ç©ºå¯¹è¯å’Œé…ç½®"):
                st.session_state.messages = []
                st.session_state.current_config["method"] = None
                st.session_state.current_config["task"] = None
                st.session_state.current_config["parameters"] = {}
                if st.session_state.chat_agent:
                    st.session_state.chat_agent.reset()
                st.rerun()
        
        with col2:
            if st.button("âš™ï¸ é…ç½®", use_container_width=True, help="æ‰“å¼€é…ç½®é¢æ¿"):
                st.session_state.show_config_panel = not st.session_state.show_config_panel
                st.rerun()
        
        # åº•éƒ¨ä¿¡æ¯
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        st.markdown("""
        <div style="text-align: center; color: #718096; font-size: 0.75rem; padding: 1rem 0;">
            <div>Powered by LLM4AD Framework</div>
            <div style="margin-top: 0.5rem;">ğŸ”¬ ç§‘ç ”çº§è‡ªåŠ¨ç®—æ³•è®¾è®¡</div>
        </div>
        """, unsafe_allow_html=True)


def get_welcome_message():
    """è·å–æ¬¢è¿æ¶ˆæ¯"""
    return """**æ¬¢è¿ä½¿ç”¨ LLM4AD è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹ï¼** ğŸ‰

æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½ç®—æ³•è®¾è®¡åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ï¼š

| åŠŸèƒ½ | è¯´æ˜ |
|:---:|:---|
| ğŸ¯ **æ–¹æ³•é€‰æ‹©** | EoHã€FunSearchã€HillClimb ç­‰å¤šç§æœç´¢æ–¹æ³• |
| ğŸ“‹ **ä»»åŠ¡é…ç½®** | è£…ç®±é—®é¢˜ã€TSPã€CVRP ç­‰ä¼˜åŒ–ä»»åŠ¡ |
| âš™ï¸ **å‚æ•°è°ƒä¼˜** | çµæ´»é…ç½®é‡‡æ ·æ•°ã€ç§ç¾¤å¤§å°ç­‰å‚æ•° |
| ğŸ“Š **å®æ—¶ç›‘æ§** | å¯è§†åŒ–å±•ç¤ºè®¾è®¡è¿‡ç¨‹å’Œæ”¶æ•›æ›²çº¿ |

**å¿«é€Ÿå¼€å§‹ï¼š**
- ğŸ’¬ ç›´æ¥å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼š"ç”¨ EoH è§£å†³åœ¨çº¿è£…ç®±é—®é¢˜"
- â“ æˆ–è€…è¯¢é—®ï¼š"æœ‰å“ªäº›å¯ç”¨çš„æ–¹æ³•ï¼Ÿ"

âš ï¸ **æç¤º**ï¼šè¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key
"""


def render_chat_message(role: str, content: str, tool_calls: str = None):
    """æ¸²æŸ“èŠå¤©æ¶ˆæ¯ - ä½¿ç”¨ Streamlit åŸç”Ÿç»„ä»¶"""
    avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"
    
    with st.chat_message(role, avatar=avatar):
        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨å¾½ç« 
        if tool_calls and role == "assistant":
            badges = [tc.strip().replace("ğŸ”§ è°ƒç”¨äº† ", "").replace("`", "") 
                     for tc in tool_calls.split('\n') if tc.strip()]
            if badges:
                badge_html = " ".join([f'<span style="background: linear-gradient(135deg, #4299e1, #3182ce); color: white; padding: 0.2rem 0.6rem; border-radius: 1rem; font-size: 0.75rem; margin-right: 0.5rem;">{b}</span>' for b in badges])
                st.markdown(badge_html, unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå†…å®¹
        if content:
            st.markdown(content)


def process_user_input(user_input: str):
    """å¤„ç†ç”¨æˆ·è¾“å…¥ - é€šè¿‡ LLM å’Œå·¥å…·è°ƒç”¨å®ç°"""
    config = st.session_state.current_config
    
    # è·å– API é…ç½®
    api_key = config.get("llm", {}).get("outer", {}).get("key", "")
    
    # å¦‚æœæœ‰ API Keyï¼Œä½¿ç”¨ ToolCallingAgent
    if api_key:
        # ç¡®ä¿ agent å·²åˆå§‹åŒ–
        if st.session_state.chat_agent is None:
            llm_config = config.get("llm", {}).get("outer", {})
            st.session_state.chat_agent = ToolCallingAgent(
                host=llm_config.get("host", "api.bltcy.top"),
                api_key=api_key,
                model=llm_config.get("model", "gpt-4o-mini")
            )
        
        # é€šè¿‡ agent å¤„ç†
        agent = st.session_state.chat_agent
        result = agent.chat(user_input, config, st.session_state.config_manager)
        
        # åŒæ­¥é…ç½®å˜æ›´
        st.session_state.current_config = agent.current_config
        
        return result
    
    # æ²¡æœ‰ API Key æ—¶çš„ç®€å•å›é€€é€»è¾‘
    return {
        "action": "chat",
        "message": "âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Keyï¼Œç„¶åæ‰€æœ‰å¯¹è¯å°†é€šè¿‡ LLM å¤„ç†ã€‚"
    }


def run_algorithm_design():
    """è¿è¡Œç®—æ³•è®¾è®¡å¹¶æµå¼è¾“å‡º - ç²¾ç¾ç‰ˆ"""
    config = st.session_state.current_config
    
    # è·å– LLM é…ç½® - å†…å¤–å±‚ç»Ÿä¸€ä½¿ç”¨ä¾§è¾¹æ é…ç½®
    llm_config = config.get("llm", {}).get("outer", {})
    if not llm_config.get("key"):
        llm_config = {
            "host": st.session_state.get("api_host", "api.bltcy.top"),
            "key": st.session_state.get("api_key", ""),
            "model": st.session_state.get("api_model", "gpt-4o-mini")
        }
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = create_runner(
        method_name=config.get("method"),
        task_name=config.get("task"),
        llm_config=llm_config,
        parameters=config.get("parameters", {}),
        use_mock=False
    )
    
    # ========== ç•Œé¢å¸ƒå±€ ==========
    # é¡¶éƒ¨çŠ¶æ€
    st.markdown(f"### ğŸš€ æ­£åœ¨è¿è¡Œ: **{config.get('method')}** â†’ **{config.get('task')}**")
    status_container = st.empty()
    progress_bar = st.progress(0)
    
    # å®æ—¶ç»Ÿè®¡å¡ç‰‡
    stats_cols = st.columns(4)
    stat_iteration = stats_cols[0].empty()
    stat_best = stats_cols[1].empty()
    stat_time = stats_cols[2].empty()
    stat_rate = stats_cols[3].empty()
    
    st.markdown("---")
    
    # å·¦å³å¸ƒå±€ï¼šæ—¥å¿— + æ›²çº¿
    col_log, col_chart = st.columns([1, 1])
    
    with col_log:
        st.markdown("### ğŸ“‹ è¿­ä»£æ—¥å¿—")
        log_placeholder = st.empty()
    
    with col_chart:
        st.markdown("### ğŸ“ˆ æ”¶æ•›æ›²çº¿")
        chart_placeholder = st.empty()
    
    st.markdown("---")
    
    # æœ€ä½³ä»£ç å±•ç¤ºåŒº
    st.markdown("### ğŸ”¥ å½“å‰æœ€ä½³ç®—æ³•")
    best_info_placeholder = st.empty()
    best_code_placeholder = st.empty()
    
    # ========== æ•°æ®å­˜å‚¨ ==========
    best_result = None
    logs = []
    iteration_logs = []
    score_history = []  # ç”¨äºç»˜åˆ¶æ”¶æ•›æ›²çº¿
    best_history = []   # æœ€ä½³å¾—åˆ†å†å²
    current_best_code = None
    current_best_desc = None
    success_count = 0
    
    try:
        for update in runner.run_with_stream():
            update_type = update.get("type")
            
            if update_type == "info":
                status_container.info(f"â„¹ï¸ {update.get('message', '')}")
            
            elif update_type == "started":
                status_container.success(f"ğŸš€ {update.get('message', 'ç®—æ³•è®¾è®¡å·²å¯åŠ¨')}")
                progress_bar.progress(5)
            
            elif update_type == "iteration":
                iteration = update.get("iteration", 0)
                score = update.get("score")
                best_score = update.get("best_score")
                is_new_best = update.get("is_new_best", False)
                code = update.get("code", "")
                algorithm_desc = update.get("algorithm", "")
                docstring = update.get("docstring", "")
                elapsed = update.get("elapsed_time", 0)
                iter_time = update.get("iter_time", 0)
                
                # è®°å½•æ•°æ®
                score_history.append(score if score is not None else None)
                best_history.append(best_score if best_score is not None else (best_history[-1] if best_history else None))
                if score is not None:
                    success_count += 1
                
                # è®¡ç®—è¿›åº¦
                max_samples = config.get("parameters", {}).get("max_sample_nums", 50)
                progress = min(5 + int(90 * iteration / max_samples), 95)
                progress_bar.progress(progress)
                
                # æ›´æ–°çŠ¶æ€æ 
                score_str = f"{score:.4f}" if score is not None else "å¤±è´¥"
                best_str = f"{best_score:.4f}" if best_score is not None else "N/A"
                status_container.info(f"â³ è¿­ä»£ {iteration}/{max_samples} | å½“å‰: {score_str} | æœ€ä½³: {best_str}")
                
                # æ›´æ–°ç»Ÿè®¡å¡ç‰‡
                stat_iteration.metric("ğŸ”„ è¿­ä»£", f"{iteration}/{max_samples}")
                stat_best.metric("ğŸ† æœ€ä½³å¾—åˆ†", best_str)
                stat_time.metric("â±ï¸ è€—æ—¶", f"{elapsed:.1f}s")
                rate = f"{100*success_count/iteration:.0f}%" if iteration > 0 else "N/A"
                stat_rate.metric("âœ… æˆåŠŸç‡", rate)
                
                # æ„å»ºæ—¥å¿—æ¡ç›®
                if is_new_best:
                    log_entry = {"icon": "ğŸ†", "iter": iteration, "score": score_str, 
                                 "status": "âœ¨æ–°æœ€ä½³", "time": f"{iter_time:.2f}s", 
                                 "is_best": True, "code": code}
                    if code:
                        current_best_code = code
                        current_best_desc = algorithm_desc or docstring
                elif score is not None:
                    log_entry = {"icon": "ğŸ“Š", "iter": iteration, "score": score_str, 
                                 "status": "", "time": f"{iter_time:.2f}s", "is_best": False}
                else:
                    log_entry = {"icon": "âŒ", "iter": iteration, "score": "å¤±è´¥", 
                                 "status": "é”™è¯¯", "time": f"{iter_time:.2f}s", "is_best": False}
                
                iteration_logs.append(log_entry)
                logs.append(update)
                
                # æ›´æ–°æ—¥å¿—è¡¨æ ¼ï¼ˆæ˜¾ç¤ºæœ€è¿‘12æ¡ï¼‰
                display_logs = iteration_logs[-12:]
                log_md = "| | # | å¾—åˆ† | çŠ¶æ€ | è€—æ—¶ |\n|:---:|:---:|:---:|:---:|:---:|\n"
                for log in display_logs:
                    status_cell = f"**{log['status']}**" if log['status'] else "-"
                    score_cell = f"**{log['score']}**" if log.get('is_best') else log['score']
                    log_md += f"| {log['icon']} | {log['iter']} | {score_cell} | {status_cell} | {log['time']} |\n"
                log_placeholder.markdown(log_md)
                
                # æ›´æ–°æ”¶æ•›æ›²çº¿
                if len(score_history) > 1:
                    chart_data = pd.DataFrame({
                        'è¿­ä»£å¾—åˆ†': score_history,
                        'æœ€ä½³å¾—åˆ†': best_history
                    })
                    chart_placeholder.line_chart(chart_data, use_container_width=True)
                
                # æ›´æ–°æœ€ä½³ä»£ç å±•ç¤º
                if current_best_code:
                    if current_best_desc:
                        best_info_placeholder.success(f"**ç®—æ³•æè¿°**: {current_best_desc}")
                    with best_code_placeholder.expander(f"ğŸ“ æŸ¥çœ‹ä»£ç  (å¾—åˆ†: {best_str})", expanded=False):
                        st.code(current_best_code, language="python")
            
            elif update_type == "finished":
                best_result = update
                progress_bar.progress(100)
                status_container.success("âœ… ç®—æ³•è®¾è®¡å®Œæˆ!")
            
            elif update_type == "error":
                st.error(f"âŒ é”™è¯¯: {update.get('message', 'æœªçŸ¥é”™è¯¯')}")
                st.session_state.is_running = False
                return
        
        # ========== æœ€ç»ˆç»“æœå±•ç¤º ==========
        progress_bar.progress(100)
        status_container.success("âœ… ç®—æ³•è®¾è®¡å®Œæˆ!")
        
        if best_result:
            st.markdown("---")
            st.markdown("## ğŸ‰ æœ€ç»ˆç»“æœ")
            
            # æœ€ç»ˆç»Ÿè®¡
            final_cols = st.columns(4)
            score = best_result.get('best_score')
            score_str = f"{score:.4f}" if isinstance(score, (int, float)) else "N/A"
            final_cols[0].metric("ğŸ† æœ€ä½³å¾—åˆ†", score_str)
            final_cols[1].metric("ğŸ“Š æ€»é‡‡æ ·", best_result.get('total_samples', 'N/A'))
            total_time = best_result.get('total_time', 0)
            final_cols[2].metric("â±ï¸ æ€»è€—æ—¶", f"{total_time:.1f}s" if isinstance(total_time, (int, float)) else "N/A")
            rate = f"{100*success_count/len(logs):.0f}%" if logs else "N/A"
            final_cols[3].metric("âœ… æˆåŠŸç‡", rate)
            
            # ç®—æ³•æè¿°
            best_algorithm = best_result.get('best_algorithm')
            best_docstring = best_result.get('best_docstring')
            if best_algorithm or best_docstring:
                st.markdown("### ğŸ’¡ ç®—æ³•æè¿°")
                st.info(best_algorithm or best_docstring)
            
            # æœ€ä½³ä»£ç 
            if best_result.get('best_code'):
                st.markdown("### ğŸ”¬ æœ€ä½³ç®—æ³•ä»£ç ")
                st.code(best_result['best_code'], language="python")
                
                # ä¸‹è½½æŒ‰é’®
                col_dl1, col_dl2, _ = st.columns([1, 1, 2])
                with col_dl1:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ä»£ç ",
                        data=best_result['best_code'],
                        file_name=f"best_{config.get('task', 'alg')}.py",
                        mime="text/plain",
                        use_container_width=True
                    )
                with col_dl2:
                    log_json = json.dumps(logs, indent=2, ensure_ascii=False, default=str)
                    st.download_button(
                        label="ğŸ“‹ å¯¼å‡ºæ—¥å¿—",
                        data=log_json,
                        file_name=f"log_{config.get('task', 'alg')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
            
            # æœ€ä½³ç‰ˆæœ¬å†å²
            best_logs = [l for l in iteration_logs if l.get('is_best') and l.get('code')]
            if len(best_logs) > 1:
                with st.expander(f"ğŸ“ˆ æœ€ä½³ç‰ˆæœ¬æ¼”è¿› ({len(best_logs)} æ¬¡çªç ´)", expanded=False):
                    for i, bl in enumerate(best_logs, 1):
                        st.markdown(f"**#{i}** è¿­ä»£ {bl['iter']} | å¾—åˆ†: {bl['score']}")
                        st.code(bl['code'], language="python")
                        if i < len(best_logs):
                            st.markdown("---")
            
            # ä¿å­˜åˆ°æ¶ˆæ¯å†å²
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"ğŸ‰ **ç®—æ³•è®¾è®¡å®Œæˆï¼**\n\n- æœ€ä½³å¾—åˆ†: **{score_str}**\n- æ€»é‡‡æ ·: {best_result.get('total_samples', 'N/A')}\n- è€—æ—¶: {total_time:.1f}s"
            })
        
    except Exception as e:
        st.error(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
    
    finally:
        st.session_state.is_running = False


def render_config_panel_ui():
    """æ¸²æŸ“é…ç½®é¢æ¿ UI"""
    config = st.session_state.current_config
    config_manager = st.session_state.config_manager
    
    st.markdown("### âš™ï¸ æ‰‹åŠ¨é…ç½®")
    
    # æ–¹æ³•é€‰æ‹©
    methods = config_manager.get_available_methods()
    current_method_idx = methods.index(config["method"]) if config["method"] in methods else 0
    
    selected_method = st.selectbox(
        "é€‰æ‹©æ–¹æ³•",
        options=methods,
        index=current_method_idx if config["method"] else 0,
        key="config_method_select"
    )
    
    # ä»»åŠ¡é€‰æ‹©
    tasks = config_manager.get_available_tasks()
    current_task_idx = tasks.index(config["task"]) if config["task"] in tasks else 0
    
    selected_task = st.selectbox(
        "é€‰æ‹©ä»»åŠ¡",
        options=tasks,
        index=current_task_idx if config["task"] else 0,
        key="config_task_select"
    )
    
    # å‚æ•°è®¾ç½®
    st.markdown("#### å‚æ•°è®¾ç½®")
    params = config_manager.get_method_parameters(selected_method)
    param_values = {}
    
    for param_name, param_info in params.items():
        current_val = config.get("parameters", {}).get(param_name, param_info.get("default"))
        
        if param_info["type"] == "int":
            param_values[param_name] = st.slider(
                param_info.get("label", param_name),
                min_value=param_info.get("min", 1),
                max_value=param_info.get("max", 1000),
                value=current_val,
                help=param_info.get("help", ""),
                key=f"config_param_{param_name}"
            )
    
    # ä¿å­˜æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True, type="primary"):
            config["method"] = selected_method
            config["task"] = selected_task
            config["parameters"] = param_values
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"âœ… é…ç½®å·²ä¿å­˜ï¼\n- æ–¹æ³•: {selected_method}\n- ä»»åŠ¡: {selected_task}"
            })
            st.session_state.show_config_panel = False
            st.rerun()
    
    with col2:
        if st.button("ğŸš€ å¼€å§‹è¿è¡Œ", use_container_width=True, 
                    disabled=not (selected_method and selected_task)):
            config["method"] = selected_method
            config["task"] = selected_task
            config["parameters"] = param_values
            st.session_state.is_running = True
            st.session_state.show_config_panel = False
            st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    init_session_state()
    
    # åˆå§‹åŒ– ToolCallingAgentï¼ˆå¦‚æœæœ‰ API Keyï¼‰
    llm_config = st.session_state.current_config.get("llm", {}).get("outer", {})
    if llm_config.get("key") and st.session_state.chat_agent is None:
        st.session_state.chat_agent = ToolCallingAgent(
            host=llm_config.get("host", "api.bltcy.top"),
            api_key=llm_config.get("key", ""),
            model=llm_config.get("model", "gpt-4o-mini")
        )
    
    # åŠ è½½è‡ªå®šä¹‰ CSS
    load_custom_css()
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    render_sidebar()
    
    # ä¸»å¸ƒå±€ - åªæœ‰æ‰“å¼€é…ç½®é¢æ¿æ—¶æ‰åˆ†æ 
    if st.session_state.show_config_panel:
        col1, col2 = st.columns([2, 1])
        main_container = col1
    else:
        main_container = st.container()
    
    with main_container:
        # æ ‡é¢˜ - ç¾åŒ–ç‰ˆ
        st.markdown("""
        <h1 class="main-title">ğŸ§¬ LLM4AD</h1>
        <p class="sub-title">åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨ç®—æ³•è®¾è®¡å¹³å°</p>
        """, unsafe_allow_html=True)
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œæ˜¾ç¤ºç®—æ³•è®¾è®¡è¿‡ç¨‹
        if st.session_state.is_running:
            run_algorithm_design()
        else:
            # æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯æˆ–å†å²
            if not st.session_state.messages:
                # åªæ˜¾ç¤ºä¸€ä¸ªæ¬¢è¿å¡ç‰‡
                st.markdown(get_welcome_message())
            
            # æ˜¾ç¤ºå†å²æ¶ˆæ¯
            for msg in st.session_state.messages:
                tool_calls = msg.get("tool_calls", "")
                render_chat_message(msg["role"], msg["content"], tool_calls)
            
            # èŠå¤©è¾“å…¥
            st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
            if prompt := st.chat_input("ğŸ’¬ è¾“å…¥æ‚¨çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼šç”¨ EoH è§£å†³åœ¨çº¿è£…ç®±é—®é¢˜"):
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                render_chat_message("user", prompt)
                
                # å¤„ç†è¾“å…¥
                with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
                    response = process_user_input(prompt)
                
                # å¤„ç†å“åº”
                action = response.get("action", "chat")
                message = response.get("message", "")
                tool_calls = response.get("tool_calls", "")
                
                if action == "run_algorithm":
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": message,
                        "tool_calls": tool_calls
                    })
                    st.session_state.is_running = True
                    st.rerun()
                else:
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": message,
                        "tool_calls": tool_calls
                    })
                    render_chat_message("assistant", message, tool_calls)
                    st.rerun()
    
    # é…ç½®é¢æ¿ï¼ˆåªåœ¨æ‰“å¼€æ—¶æ˜¾ç¤ºåœ¨å³ä¾§ï¼‰
    if st.session_state.show_config_panel:
        with col2:
            render_config_panel_ui()


if __name__ == "__main__":
    main()
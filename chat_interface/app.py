"""
LLM4AD Chat Interface - Main Application
ä¸€ä¸ªåŸºäºå¯¹è¯çš„è‡ªåŠ¨ç®—æ³•è®¾è®¡äº¤äº’ç•Œé¢

æ‰€æœ‰å¯¹è¯éƒ½é€šè¿‡å¤–éƒ¨LLMå®ç°ï¼Œä½¿ç”¨OpenAI Function Callingé£æ ¼çš„å·¥å…·è°ƒç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
    cd LLM4AD
    streamlit run chat_interface/app.py
"""

import os
import sys
import time
import json
import streamlit as st
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from chat_interface.tool_agent import ToolCallingAgent
from chat_interface.config_manager import ConfigManager
from chat_interface.algorithm_runner import create_runner

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="LLM4AD - è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)


def init_session_state():
    """åˆå§‹åŒ– session state"""
    defaults = {
        "messages": [],
        "chat_agent": None,
        "config_manager": ConfigManager(),
        "current_config": {
            "method": None,
            "task": None,
            "llm": {"outer": {}, "inner": {}},
            "parameters": {}
        },
        "is_running": False,
        "show_config_panel": False,
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("## âš™ï¸ é…ç½®")
        
        st.markdown("---")
        
        # LLM é…ç½®
        st.markdown("### ğŸ¤– LLM è®¾ç½®")
        st.markdown("*å¤–éƒ¨å¯¹è¯ + å†…éƒ¨ç®—æ³•è®¾è®¡éƒ½ä½¿ç”¨æ­¤ API*")
        
        api_host = st.text_input(
            "API Host", 
            value=st.session_state.current_config["llm"].get("outer", {}).get("host", "api.bltcy.top"),
            key="api_host"
        )
        
        api_key = st.text_input(
            "API Key", 
            type="password",
            value=st.session_state.current_config["llm"].get("outer", {}).get("key", ""),
            key="api_key",
            help="OpenAI å…¼å®¹çš„ API Key"
        )
        
        api_model = st.selectbox(
            "æ¨¡å‹",
            ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo", "deepseek-chat"],
            key="api_model"
        )
        
        # æ›´æ–°é…ç½®
        st.session_state.current_config["llm"] = {
            "outer": {"host": api_host, "key": api_key, "model": api_model},
            "inner": {"host": api_host, "key": api_key, "model": api_model}
        }
        
        # å¦‚æœ API Key å˜äº†ï¼Œé‡ç½® agent
        if api_key and st.session_state.chat_agent:
            if st.session_state.chat_agent.api_key != api_key:
                st.session_state.chat_agent = None
        
        st.markdown("---")
        
        # å½“å‰çŠ¶æ€
        st.markdown("### ğŸ“Š å½“å‰çŠ¶æ€")
        config = st.session_state.current_config
        
        method = config.get("method")
        task = config.get("task")
        
        if method:
            st.success(f"âœ… æ–¹æ³•: {method}")
        else:
            st.warning("âŒ æ–¹æ³•: æœªé€‰æ‹©")
            
        if task:
            st.success(f"âœ… ä»»åŠ¡: {task}")
        else:
            st.warning("âŒ ä»»åŠ¡: æœªé€‰æ‹©")
        
        if st.session_state.is_running:
            st.info("ğŸ”„ è¿è¡Œä¸­...")
        
        st.markdown("---")
        
        # å¿«æ·æ“ä½œ
        st.markdown("### ğŸš€ å¿«æ·æ“ä½œ")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True):
                st.session_state.messages = []
                st.session_state.current_config["method"] = None
                st.session_state.current_config["task"] = None
                st.session_state.current_config["parameters"] = {}
                st.rerun()
        
        with col2:
            if st.button("âš™ï¸ é…ç½®", use_container_width=True):
                st.session_state.show_config_panel = not st.session_state.show_config_panel
                st.rerun()


def get_welcome_message():
    """è·å–æ¬¢è¿æ¶ˆæ¯"""
    return """
ğŸ‘‹ **æ¬¢è¿ä½¿ç”¨ LLM4AD è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹ï¼**

æˆ‘æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ï¼š
- ğŸ¯ é€‰æ‹©ç®—æ³•è®¾è®¡æ–¹æ³•ï¼ˆå¦‚ EoHã€FunSearch ç­‰ï¼‰
- ğŸ“‹ é…ç½®ä¼˜åŒ–ä»»åŠ¡ï¼ˆå¦‚è£…ç®±é—®é¢˜ã€TSP ç­‰ï¼‰
- âš™ï¸ è®¾ç½®å‚æ•°å¹¶è¿è¡Œç®—æ³•è®¾è®¡
- ğŸ“Š å®æ—¶å±•ç¤ºè®¾è®¡è¿‡ç¨‹å’Œæœ€ç»ˆç»“æœ

**å¼€å§‹æ–¹å¼ï¼ˆæ‰€æœ‰å¯¹è¯éƒ½ç”± LLM å¤„ç†ï¼‰ï¼š**
- ç›´æ¥æè¿°æ‚¨çš„éœ€æ±‚ï¼Œä¾‹å¦‚ï¼š"æˆ‘æƒ³ç”¨EoHæ–¹æ³•è§£å†³åœ¨çº¿è£…ç®±é—®é¢˜"
- æˆ–è¯¢é—®ï¼š"æœ‰å“ªäº›å¯ç”¨çš„æ–¹æ³•ï¼Ÿ"ã€"ä»€ä¹ˆä»»åŠ¡é€‚åˆæˆ‘çš„åœºæ™¯ï¼Ÿ"

âš ï¸ **è¯·å…ˆåœ¨å·¦ä¾§è¾¹æ é…ç½® API Key**ï¼Œç„¶åå¼€å§‹å¯¹è¯ã€‚
"""


def process_user_input(user_input: str):
    """å¤„ç†ç”¨æˆ·è¾“å…¥ - é€šè¿‡ LLM å’Œå·¥å…·è°ƒç”¨å®ç°"""
    config = st.session_state.current_config
    
    # è·å– API é…ç½®
    api_key = config.get("llm", {}).get("outer", {}).get("key", "")
    
    # å¦‚æœæœ‰ API Keyï¼Œä½¿ç”¨ ToolCallingAgent
    if api_key:
        # ç¡®ä¿ agent å·²åˆå§‹åŒ–
        if st.session_state.chat_agent is None:
            llm_config = config.get("llm", {}).get("outer", {})
            st.session_state.chat_agent = ToolCallingAgent(
                host=llm_config.get("host", "api.bltcy.top"),
                api_key=api_key,
                model=llm_config.get("model", "gpt-4o-mini")
            )
        
        # é€šè¿‡ agent å¤„ç†
        agent = st.session_state.chat_agent
        result = agent.chat(user_input, config, st.session_state.config_manager)
        
        # åŒæ­¥é…ç½®å˜æ›´
        st.session_state.current_config = agent.current_config
        
        return result
    
    # æ²¡æœ‰ API Key æ—¶çš„ç®€å•å›é€€é€»è¾‘
    return {
        "action": "chat",
        "message": "âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Keyï¼Œç„¶åæ‰€æœ‰å¯¹è¯å°†é€šè¿‡ LLM å¤„ç†ã€‚"
    }


def run_algorithm_design():
    """è¿è¡Œç®—æ³•è®¾è®¡å¹¶æµå¼è¾“å‡º - ç²¾ç¾ç‰ˆ"""
    config = st.session_state.current_config
    
    # è·å– LLM é…ç½® - å†…å¤–å±‚ç»Ÿä¸€ä½¿ç”¨ä¾§è¾¹æ é…ç½®
    llm_config = config.get("llm", {}).get("outer", {})
    if not llm_config.get("key"):
        llm_config = {
            "host": st.session_state.get("api_host", "api.bltcy.top"),
            "key": st.session_state.get("api_key", ""),
            "model": st.session_state.get("api_model", "gpt-4o-mini")
        }
    
    # åˆ›å»ºè¿è¡Œå™¨
    runner = create_runner(
        method_name=config.get("method"),
        task_name=config.get("task"),
        llm_config=llm_config,
        parameters=config.get("parameters", {}),
        use_mock=False
    )
    
    # ========== ç•Œé¢å¸ƒå±€ ==========
    # é¡¶éƒ¨çŠ¶æ€
    st.markdown(f"### ğŸš€ æ­£åœ¨è¿è¡Œ: **{config.get('method')}** â†’ **{config.get('task')}**")
    status_container = st.empty()
    progress_bar = st.progress(0)
    
    # å®æ—¶ç»Ÿè®¡å¡ç‰‡
    stats_cols = st.columns(4)
    stat_iteration = stats_cols[0].empty()
    stat_best = stats_cols[1].empty()
    stat_time = stats_cols[2].empty()
    stat_rate = stats_cols[3].empty()
    
    st.markdown("---")
    
    # å·¦å³å¸ƒå±€ï¼šæ—¥å¿— + æ›²çº¿
    col_log, col_chart = st.columns([1, 1])
    
    with col_log:
        st.markdown("### ğŸ“‹ è¿­ä»£æ—¥å¿—")
        log_placeholder = st.empty()
    
    with col_chart:
        st.markdown("### ğŸ“ˆ æ”¶æ•›æ›²çº¿")
        chart_placeholder = st.empty()
    
    st.markdown("---")
    
    # æœ€ä½³ä»£ç å±•ç¤ºåŒº
    st.markdown("### ğŸ”¥ å½“å‰æœ€ä½³ç®—æ³•")
    best_info_placeholder = st.empty()
    best_code_placeholder = st.empty()
    
    # ========== æ•°æ®å­˜å‚¨ ==========
    best_result = None
    logs = []
    iteration_logs = []
    score_history = []  # ç”¨äºç»˜åˆ¶æ”¶æ•›æ›²çº¿
    best_history = []   # æœ€ä½³å¾—åˆ†å†å²
    current_best_code = None
    current_best_desc = None
    success_count = 0
    
    try:
        for update in runner.run_with_stream():
            update_type = update.get("type")
            
            if update_type == "info":
                status_container.info(f"â„¹ï¸ {update.get('message', '')}")
            
            elif update_type == "started":
                status_container.success(f"ğŸš€ {update.get('message', 'ç®—æ³•è®¾è®¡å·²å¯åŠ¨')}")
                progress_bar.progress(5)
            
            elif update_type == "iteration":
                iteration = update.get("iteration", 0)
                score = update.get("score")
                best_score = update.get("best_score")
                is_new_best = update.get("is_new_best", False)
                code = update.get("code", "")
                algorithm_desc = update.get("algorithm", "")
                docstring = update.get("docstring", "")
                elapsed = update.get("elapsed_time", 0)
                iter_time = update.get("iter_time", 0)
                
                # è®°å½•æ•°æ®
                score_history.append(score if score is not None else None)
                best_history.append(best_score if best_score is not None else (best_history[-1] if best_history else None))
                if score is not None:
                    success_count += 1
                
                # è®¡ç®—è¿›åº¦
                max_samples = config.get("parameters", {}).get("max_sample_nums", 50)
                progress = min(5 + int(90 * iteration / max_samples), 95)
                progress_bar.progress(progress)
                
                # æ›´æ–°çŠ¶æ€æ 
                score_str = f"{score:.4f}" if score is not None else "å¤±è´¥"
                best_str = f"{best_score:.4f}" if best_score is not None else "N/A"
                status_container.info(f"â³ è¿­ä»£ {iteration}/{max_samples} | å½“å‰: {score_str} | æœ€ä½³: {best_str}")
                
                # æ›´æ–°ç»Ÿè®¡å¡ç‰‡
                stat_iteration.metric("ğŸ”„ è¿­ä»£", f"{iteration}/{max_samples}")
                stat_best.metric("ğŸ† æœ€ä½³å¾—åˆ†", best_str)
                stat_time.metric("â±ï¸ è€—æ—¶", f"{elapsed:.1f}s")
                rate = f"{100*success_count/iteration:.0f}%" if iteration > 0 else "N/A"
                stat_rate.metric("âœ… æˆåŠŸç‡", rate)
                
                # æ„å»ºæ—¥å¿—æ¡ç›®
                if is_new_best:
                    log_entry = {"icon": "ğŸ†", "iter": iteration, "score": score_str, 
                                 "status": "âœ¨æ–°æœ€ä½³", "time": f"{iter_time:.2f}s", 
                                 "is_best": True, "code": code}
                    if code:
                        current_best_code = code
                        current_best_desc = algorithm_desc or docstring
                elif score is not None:
                    log_entry = {"icon": "ğŸ“Š", "iter": iteration, "score": score_str, 
                                 "status": "", "time": f"{iter_time:.2f}s", "is_best": False}
                else:
                    log_entry = {"icon": "âŒ", "iter": iteration, "score": "å¤±è´¥", 
                                 "status": "é”™è¯¯", "time": f"{iter_time:.2f}s", "is_best": False}
                
                iteration_logs.append(log_entry)
                logs.append(update)
                
                # æ›´æ–°æ—¥å¿—è¡¨æ ¼ï¼ˆæ˜¾ç¤ºæœ€è¿‘12æ¡ï¼‰
                display_logs = iteration_logs[-12:]
                log_md = "| | # | å¾—åˆ† | çŠ¶æ€ | è€—æ—¶ |\n|:---:|:---:|:---:|:---:|:---:|\n"
                for log in display_logs:
                    status_cell = f"**{log['status']}**" if log['status'] else "-"
                    score_cell = f"**{log['score']}**" if log.get('is_best') else log['score']
                    log_md += f"| {log['icon']} | {log['iter']} | {score_cell} | {status_cell} | {log['time']} |\n"
                log_placeholder.markdown(log_md)
                
                # æ›´æ–°æ”¶æ•›æ›²çº¿
                if len(score_history) > 1:
                    chart_data = pd.DataFrame({
                        'è¿­ä»£å¾—åˆ†': score_history,
                        'æœ€ä½³å¾—åˆ†': best_history
                    })
                    chart_placeholder.line_chart(chart_data, use_container_width=True)
                
                # æ›´æ–°æœ€ä½³ä»£ç å±•ç¤º
                if current_best_code:
                    if current_best_desc:
                        best_info_placeholder.success(f"**ç®—æ³•æè¿°**: {current_best_desc}")
                    with best_code_placeholder.expander(f"ğŸ“ æŸ¥çœ‹ä»£ç  (å¾—åˆ†: {best_str})", expanded=False):
                        st.code(current_best_code, language="python")
            
            elif update_type == "finished":
                best_result = update
                progress_bar.progress(100)
                status_container.success("âœ… ç®—æ³•è®¾è®¡å®Œæˆ!")
            
            elif update_type == "error":
                st.error(f"âŒ é”™è¯¯: {update.get('message', 'æœªçŸ¥é”™è¯¯')}")
                st.session_state.is_running = False
                return
        
        # ========== æœ€ç»ˆç»“æœå±•ç¤º ==========
        progress_bar.progress(100)
        status_container.success("âœ… ç®—æ³•è®¾è®¡å®Œæˆ!")
        
        if best_result:
            st.markdown("---")
            st.markdown("## ğŸ‰ æœ€ç»ˆç»“æœ")
            
            # æœ€ç»ˆç»Ÿè®¡
            final_cols = st.columns(4)
            score = best_result.get('best_score')
            score_str = f"{score:.4f}" if isinstance(score, (int, float)) else "N/A"
            final_cols[0].metric("ğŸ† æœ€ä½³å¾—åˆ†", score_str)
            final_cols[1].metric("ğŸ“Š æ€»é‡‡æ ·", best_result.get('total_samples', 'N/A'))
            total_time = best_result.get('total_time', 0)
            final_cols[2].metric("â±ï¸ æ€»è€—æ—¶", f"{total_time:.1f}s" if isinstance(total_time, (int, float)) else "N/A")
            rate = f"{100*success_count/len(logs):.0f}%" if logs else "N/A"
            final_cols[3].metric("âœ… æˆåŠŸç‡", rate)
            
            # ç®—æ³•æè¿°
            best_algorithm = best_result.get('best_algorithm')
            best_docstring = best_result.get('best_docstring')
            if best_algorithm or best_docstring:
                st.markdown("### ğŸ’¡ ç®—æ³•æè¿°")
                st.info(best_algorithm or best_docstring)
            
            # æœ€ä½³ä»£ç 
            if best_result.get('best_code'):
                st.markdown("### ğŸ”¬ æœ€ä½³ç®—æ³•ä»£ç ")
                st.code(best_result['best_code'], language="python")
                
                # ä¸‹è½½æŒ‰é’®
                col_dl1, col_dl2, _ = st.columns([1, 1, 2])
                with col_dl1:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ä»£ç ",
                        data=best_result['best_code'],
                        file_name=f"best_{config.get('task', 'alg')}.py",
                        mime="text/plain",
                        use_container_width=True
                    )
                with col_dl2:
                    log_json = json.dumps(logs, indent=2, ensure_ascii=False, default=str)
                    st.download_button(
                        label="ğŸ“‹ å¯¼å‡ºæ—¥å¿—",
                        data=log_json,
                        file_name=f"log_{config.get('task', 'alg')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
            
            # æœ€ä½³ç‰ˆæœ¬å†å²
            best_logs = [l for l in iteration_logs if l.get('is_best') and l.get('code')]
            if len(best_logs) > 1:
                with st.expander(f"ğŸ“ˆ æœ€ä½³ç‰ˆæœ¬æ¼”è¿› ({len(best_logs)} æ¬¡çªç ´)", expanded=False):
                    for i, bl in enumerate(best_logs, 1):
                        st.markdown(f"**#{i}** è¿­ä»£ {bl['iter']} | å¾—åˆ†: {bl['score']}")
                        st.code(bl['code'], language="python")
                        if i < len(best_logs):
                            st.markdown("---")
            
            # ä¿å­˜åˆ°æ¶ˆæ¯å†å²
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"ğŸ‰ **ç®—æ³•è®¾è®¡å®Œæˆï¼**\n\n- æœ€ä½³å¾—åˆ†: **{score_str}**\n- æ€»é‡‡æ ·: {best_result.get('total_samples', 'N/A')}\n- è€—æ—¶: {total_time:.1f}s"
            })
        
    except Exception as e:
        st.error(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
    
    finally:
        st.session_state.is_running = False


def render_config_panel_ui():
    """æ¸²æŸ“é…ç½®é¢æ¿ UI"""
    config = st.session_state.current_config
    config_manager = st.session_state.config_manager
    
    st.markdown("### âš™ï¸ æ‰‹åŠ¨é…ç½®")
    
    # æ–¹æ³•é€‰æ‹©
    methods = config_manager.get_available_methods()
    current_method_idx = methods.index(config["method"]) if config["method"] in methods else 0
    
    selected_method = st.selectbox(
        "é€‰æ‹©æ–¹æ³•",
        options=methods,
        index=current_method_idx if config["method"] else 0,
        key="config_method_select"
    )
    
    # ä»»åŠ¡é€‰æ‹©
    tasks = config_manager.get_available_tasks()
    current_task_idx = tasks.index(config["task"]) if config["task"] in tasks else 0
    
    selected_task = st.selectbox(
        "é€‰æ‹©ä»»åŠ¡",
        options=tasks,
        index=current_task_idx if config["task"] else 0,
        key="config_task_select"
    )
    
    # å‚æ•°è®¾ç½®
    st.markdown("#### å‚æ•°è®¾ç½®")
    params = config_manager.get_method_parameters(selected_method)
    param_values = {}
    
    for param_name, param_info in params.items():
        current_val = config.get("parameters", {}).get(param_name, param_info.get("default"))
        
        if param_info["type"] == "int":
            param_values[param_name] = st.slider(
                param_info.get("label", param_name),
                min_value=param_info.get("min", 1),
                max_value=param_info.get("max", 1000),
                value=current_val,
                help=param_info.get("help", ""),
                key=f"config_param_{param_name}"
            )
    
    # ä¿å­˜æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True, type="primary"):
            config["method"] = selected_method
            config["task"] = selected_task
            config["parameters"] = param_values
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"âœ… é…ç½®å·²ä¿å­˜ï¼\n- æ–¹æ³•: {selected_method}\n- ä»»åŠ¡: {selected_task}"
            })
            st.session_state.show_config_panel = False
            st.rerun()
    
    with col2:
        if st.button("ğŸš€ å¼€å§‹è¿è¡Œ", use_container_width=True, 
                    disabled=not (selected_method and selected_task)):
            config["method"] = selected_method
            config["task"] = selected_task
            config["parameters"] = param_values
            st.session_state.is_running = True
            st.session_state.show_config_panel = False
            st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    init_session_state()
    
    # åˆå§‹åŒ– ToolCallingAgentï¼ˆå¦‚æœæœ‰ API Keyï¼‰
    llm_config = st.session_state.current_config.get("llm", {}).get("outer", {})
    if llm_config.get("key") and st.session_state.chat_agent is None:
        st.session_state.chat_agent = ToolCallingAgent(
            host=llm_config.get("host", "api.bltcy.top"),
            api_key=llm_config.get("key", ""),
            model=llm_config.get("model", "gpt-4o-mini")
        )
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    render_sidebar()
    
    # ä¸»å¸ƒå±€
    if st.session_state.show_config_panel:
        col1, col2 = st.columns([2, 1])
    else:
        col1, col2 = st.columns([3, 1])
    
    with col1:
        # æ ‡é¢˜
        st.markdown("# ğŸ§¬ LLM4AD è‡ªåŠ¨ç®—æ³•è®¾è®¡åŠ©æ‰‹")
        st.markdown("*é€šè¿‡å¯¹è¯çš„æ–¹å¼ï¼Œè®©AIå¸®æ‚¨è®¾è®¡é«˜æ•ˆçš„ç®—æ³•*")
        st.markdown("---")
        
        # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œæ˜¾ç¤ºç®—æ³•è®¾è®¡è¿‡ç¨‹
        if st.session_state.is_running:
            run_algorithm_design()
        else:
            # æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯æˆ–å†å²
            if not st.session_state.messages:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(get_welcome_message())
            
            # æ˜¾ç¤ºå†å²æ¶ˆæ¯
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"], avatar="ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"):
                    st.markdown(msg["content"])
            
            # èŠå¤©è¾“å…¥
            if prompt := st.chat_input("è¾“å…¥æ‚¨çš„éœ€æ±‚..."):
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                with st.chat_message("user", avatar="ğŸ‘¤"):
                    st.markdown(prompt)
                
                # å¤„ç†è¾“å…¥
                with st.spinner("æ€è€ƒä¸­..."):
                    response = process_user_input(prompt)
                
                # å¤„ç†å“åº”
                action = response.get("action", "chat")
                message = response.get("message", "")
                tool_calls = response.get("tool_calls", "")
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ˜¾ç¤º
                if tool_calls:
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.caption(tool_calls)
                
                if action == "run_algorithm":
                    st.session_state.messages.append({"role": "assistant", "content": message})
                    st.session_state.is_running = True
                    st.rerun()
                else:
                    st.session_state.messages.append({"role": "assistant", "content": message})
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.markdown(message)
                    st.rerun()
    
    with col2:
        if st.session_state.show_config_panel:
            render_config_panel_ui()


if __name__ == "__main__":
    main()
